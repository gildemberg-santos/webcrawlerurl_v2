# Web Crawler para extração de dados

O objetivo deste projeto é fornecer uma ferramenta automatizada para coletar informações específicas de uma página da web. Nós utilizamos técnicas de mapeamento e extração de dados para analisar a estrutura da página e identificar padrões na apresentação de dados, permitindo que os dados sejam extraídos e organizados em uma estrutura de dados útil.

### Instalação

Para instalar o projeto, você precisa clonar o repositório do Github:

``` shell
$ git clone git@github.com:gildemberg-santos/webcrawlerurl_v2.git
```

### Iniciando o conteiner

Para iniciar o conteiner, basta executar o seguinte comando:

``` start
$ make start
```

### Parando o conteiner

Se você precisar parar o conteiner, basta executar o seguinte comando:

``` stop
$ make stop
```

### Executando o serviço

Para executar o serviço, basta executar o seguinte comando:

``` run
$ make run
```

ou

``` dev
$ make dev
```

### Executando os testes

Para executar todos os testes, basta executar o seguinte comando:

``` test
$ make test
```

### Executando o build do projeto

Para executar o build, basta executar o seguinte comando:

``` build
$ make build
```

Com estes comandos, você pode facilmente instalar, iniciar e executar o nosso web crawler para extração de dados. Divirta-se coletando informações úteis da web!
